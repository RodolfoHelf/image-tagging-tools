{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bhEVe0JFcuu_"
      },
      "source": [
        "# Getting Dataset from Mega"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Check if notebook is running on Kaggle or Collab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "# get current directory\n",
        "# If directory == /contet, than is Collab. If directory == /kaggle/working, than is Kaggle\n",
        "input_directory = os.getcwd()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Mount Google Drive\n",
        "Mount your google drive to be used for storing the dataset into it. Note: This step is optional, the dataset can also be saved to Colab session storage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONxui2_ccuvK",
        "outputId": "464ce773-3a3e-4ff8-8625-4c08c0008e4b"
      },
      "outputs": [],
      "source": [
        "# Check if notebook is running on Collab\n",
        "if input_directory == \"/content\":\n",
        "    from google.colab import drive\n",
        "    drive.mount._DEBUG = False\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "else:\n",
        "    print(\"Kaggle does not support google.collab package\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Mega CMD Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mega CMD Requirements\n",
        "!apt-get update\n",
        "!apt install libmms0 libc-ares2 libc6 libcrypto++6 libgcc1 libmediainfo0v5 libpcre3 libpcrecpp0v5 libssl1.1 libstdc++6 libtinyxml2-6a libzen0v5 zlib1g apt-transport-https -y\n",
        "!apt --fix-broken install -y\n",
        "\n",
        "# Mega CMD Download and Installation\n",
        "!wget https://mega.nz/linux/MEGAsync/xUbuntu_18.04/amd64/megacmd-xUbuntu_18.04_amd64.deb\n",
        "!sudo dpkg -i megacmd-xUbuntu_18.04_amd64.deb"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Download Dataset\n",
        "Set download URL in Mega and destination path (in Google Drive or session storage) and download the file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import contextlib\n",
        "from subprocess import Popen, PIPE, STDOUT\n",
        "\n",
        "# Download URL on Mega\n",
        "tagged_dataset_url = 'https://mega.nz/file/8RhFRISJ#vlQhjBp5hrNtQzFnRVQtD_ilHfIyLOSrlwVXEb3t1UM'\n",
        "other_dataset_url  = 'https://mega.nz/file/5FhGkRjD#yFihfhr1RMHfPTffhPB4tQtJsnn_HBYFOSfqdPOrp78'\n",
        "# Destination path for download\n",
        "destination_path = './downloads'\n",
        "os.makedirs(destination_path, exist_ok=True)\n",
        "\n",
        "# Function for printing the download progress\n",
        "def print_progress(proc, stream='stdout'):\n",
        "  newlines = ['\\n', '\\r\\n', '\\r']\n",
        "  stream = getattr(proc, stream)\n",
        "  with contextlib.closing(stream):\n",
        "      while True:\n",
        "          out = []\n",
        "          last = stream.read(1)\n",
        "          # Don't loop forever\n",
        "          if last == '' and proc.poll() is not None:\n",
        "              break\n",
        "          while last not in newlines:\n",
        "              # Don't loop forever\n",
        "              if last == '' and proc.poll() is not None:\n",
        "                  break\n",
        "              out.append(last)\n",
        "              last = stream.read(1)\n",
        "          out = ''.join(out)\n",
        "          yield out\n",
        "\n",
        "# Download dataset\n",
        "for data_url in [tagged_dataset_url, other_dataset_url]:\n",
        "  cmd = [\"mega-get\", data_url, destination_path]\n",
        "  proc = Popen(cmd,stdout=PIPE, stderr=STDOUT, universal_newlines=True)\n",
        "  for line in print_progress(proc):\n",
        "    print(line)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFI20pLVcuvU"
      },
      "source": [
        "# Fetch & Clone Repo\n",
        "\n",
        "Clone the `image-tagging-tools` repo as it has all the required utils and codes from preprocessing the image datasets to training the models and using them to classify the images. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6n6QEB49cuvV",
        "outputId": "694d6054-03f6-4fda-9836-cc6dad61811b"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/kk-digital/image-tagging-tools.git\n",
        "%cd image-tagging-tools"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6hYcmeZicuvW"
      },
      "source": [
        "# Preprocess the Dataset images (Stage 1)\n",
        "\n",
        "Process a tagged dataset and computes the images metadata along with its CLIP embeddings and writes the result into a JSON file in specified output folder. In addition, the SQLite database named `dataset_cache.sqlite` with table named `dataset_cache` containing file name, hash and file path for dataset images will be created in the `./output` folder. "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "guwuN0UncuvW"
      },
      "source": [
        "### Install Requirements "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86S-QyvSnwG8"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install ascii_graph open_clip_torch patool fire"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Extract Downloaded ZIP-Archived Data (Optional)\n",
        "This step is optional. If this step is not performed, Stage 1 will perform the extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "# Specify location of downloaded data (zip file)\n",
        "downloaded_data_zip = input_directory + '/downloads/pixel-art-tagged-v3.zip'\n",
        "# Location to extract the zip file to\n",
        "dataset_path = f'./datasets/{os.path.splitext(os.path.split(downloaded_data_zip)[-1])[0]}'\n",
        "\n",
        "with ZipFile(downloaded_data_zip) as zip_object:\n",
        "    zip_object.extractall(dataset_path)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "hiqXMqOEcuvX"
      },
      "source": [
        "### Import the Module/Utility "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "usaH8e-fcuvY"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.insert(0, './image-tagging-pipeline/data_loader/')\n",
        "sys.path.insert(0, './image-tagging-pipeline/train/')\n",
        "sys.path.insert(0, './image-tagging-pipeline/classify/')\n",
        "sys.path.insert(0, './image-tagging-pipeline/classify_zip/')\n",
        "from ImageDatasetProcessor import ImageDatasetProcessor\n",
        "from classify import main as classify_main\n",
        "from classify_zip import main as classify_main_zip\n",
        "from classify_zip import zip_gen as zip_generator\n",
        "from train import main as train_main\n",
        "from classify_helper_functions import *\n",
        "import patoolib\n",
        "import shutil"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "LeIimd1gcuvY"
      },
      "source": [
        "### Set Required Variables by the Utility\n",
        "\n",
        "Initialize the required parameters needed by the dataset preprocessor utility and they are described as follows: \n",
        "\n",
        "* `input_folder` _[str]_ -  path to the directory containing sub-folders of each tag.\n",
        "* `output_folder` _[str]_ - path to the directory where to save the files into it.\n",
        "* `clip_model` _[str]_ - CLIP model to be used\n",
        "* `pretrained` _[str]_ - the pre-trained model to be used for CLIP\n",
        "* `batch_size` _[int]_ -  number of images to process at a time\n",
        "* `num_threads` _[int]_ - the number to be used in this process\n",
        "* `device` _[str]_ -  the device to be used in computing the CLIP embeddings, if `None` is provided then `cuda` will be used if available\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFReXmwmcuvY"
      },
      "outputs": [],
      "source": [
        "# Specify the path to the dataset in dataset_path variable\n",
        "# dataset_path = '/content/downloads/pixel-art-tagged-v3.zip'\n",
        "dataset_path = './datasets/testdata.zip'\n",
        "output_folder = './output'\n",
        "tagged_dataset = True\n",
        "clip_model = 'ViT-L-14'\n",
        "pretrained = 'openai'\n",
        "batch_size = 32\n",
        "num_threads = 4\n",
        "device = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D691ZEnrcuvZ"
      },
      "source": [
        "### Run the Preprocessor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZPLvQ1EcuvZ",
        "outputId": "314a1c84-f94f-4513-ad23-98f94cf03c3a"
      },
      "outputs": [],
      "source": [
        "ImageDatasetProcessor.process_dataset(\n",
        "    dataset_path, \n",
        "    output_folder,\n",
        "    tagged_dataset, \n",
        "    clip_model, \n",
        "    pretrained,\n",
        "    batch_size, \n",
        "    num_threads, \n",
        "    device\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Train the Classifiers (Stage 2)\n",
        "Given a `metadata` json file containing embeddings for images and `tag-to-image-hash` json file containing images' hash with tags, the script start to make for every tag two binary classification models and save it in output folder."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Ld8q1avSOdOP"
      },
      "source": [
        "### Train Script Variables\n",
        "\n",
        "* `metadata_json` _[string]_ - _[required]_ - The path to the metadata json file. \n",
        "* `tag_to_hash_json` _[string]_ - _[required]_ - The path to tag-to-hash json file. \n",
        "* `output` _[string]_ - _[optional]_ - The path to the output directory.\n",
        "* `test_per` _[float]_ - _[optional]_ - The percentage of the test images from the dataset, default = 0.1 \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYigdGm_PHLm"
      },
      "outputs": [],
      "source": [
        "# Run from ./image-tagging-tools directory\n",
        "metadata_json = './output/input-metadata.json' \n",
        "tag_to_hash_json = './output/input-tag-to-image-hash-list.json'\n",
        "output_dir = './output'\n",
        "test_per = 0.1"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8GLoJWDJS1vm"
      },
      "source": [
        "### Run the Training Script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjWOmPV1-3Zz",
        "outputId": "8f7599aa-1beb-4535-a2c4-21021cc1692e"
      },
      "outputs": [],
      "source": [
        "train_main(\n",
        "    metadata_json = metadata_json,\n",
        "    tag_to_hash_json = tag_to_hash_json,\n",
        "    output_dir = output_dir,\n",
        "    test_per = test_per\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get List of Type and Tag Pairs from All Models'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from model_api.model_api import ModelApi\n",
        "# Creating model object\n",
        "model_api = ModelApi()\n",
        "type_tag_pair = model_api.get_type_tag_pair() \n",
        "print (type_tag_pair)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Classify Data (Stage 3)\n",
        "Running the classifier (note: this stage does not process .zip (archived) file, For .zip (archived) data continue to Stage 4). The script will loop over every image and make the classification for it using every binary classification model. Running the classifier can be performed from command line interface (CLI) or within Python runtime as shown in the following examples."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Running the classifier from Command Line Interface (CLI Version)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python ./image-tagging-pipeline/classify/classify.py --directory=$dataset_path --metadata_json=./output/input-metadata.json --output=./output --output_bins=10 --model_type=ovr-logistic-regression --tag=not-pixel-art"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VtcQghX_S5YD"
      },
      "source": [
        "### CLI Arguments\n",
        "\n",
        "* `directory` _[string]_ - _[required]_ - The path to the images' folder or images' .zip file. \n",
        "* `metadata_json` _[string]_ - _[required]_ - The path to the metadata json file for CLIP embeddings. \n",
        "* `output` _[string]_ - _[optional]_ - The path to the output directory for the inference results. \n",
        "* `model_type` _[string]_ - _[required]_ - The type of the model (example: `ovr-logistic-regression`, `ovr-svm`, `torch-logistic-regression`).\n",
        "* `tag` _[string]_ - _[required]_ - Tag string (example: `pos-character`, `pos-environmental-space`, etc).\n",
        "* `output_bins` _[int]_ - _[optional]_ -  The number of bins of the results for each model.\n",
        "\n",
        "If the `--output` argument is not specified, the classification / inference result will be placed at `./output/tagging_output` folder. Time stamp will be appended to folder name (for example: `./output/tagging_output_2023_1_21_0_56`).\n",
        "In addition, the SQLite database named `score_cache.sqlite` with table named `score_cache` containing file name, file path, file hash, model name, model type, model train date, tag string and tag score for given images will be created in the `./output` folder. \n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Running the Classifier (from Python Runtime)\n",
        "\n",
        "### Variables for Classifier\n",
        "* `data_path` _[string]_ - _[required]_ - The path to the images data folder or single image file'. \n",
        "* `json_file_path` _[string]_ - _[required]_ - The path to the metadata json file for CLIP embeddings. \n",
        "* `output_dir` _[string]_ - _[optional]_ - The path to the output directory for the inference results. \n",
        "* `model_type` _[string]_ - _[required]_ - The type of the model (example: `ovr-logistic-regression`, `ovr-svm`, `torch-logistic-regression`)\n",
        "* `tag` _[string]_ - _[required]_ - Tag string (example: `pos-character`, `pos-environmental-space`, etc).\n",
        "* `bins_number` _[int]_ - _[optional]_ -  The number of bins of the results for each model."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Classify Images Data in Folder with Single Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Specify path to folder containing images data in data_path variable\n",
        "# data_path = '../path/to/image/data/folder/'\n",
        "# Or test with images in dataset\n",
        "data_path    = dataset_path\n",
        "output_dir     = './output/classification_single_image_single_model'\n",
        "json_file_path = './output/input-metadata.json'\n",
        "bins_number    = 10\n",
        "# Specify the type of model\n",
        "model_type = 'ovr-logistic-regression'\n",
        "# Specify the tag string\n",
        "tag = 'not-pixel-art'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "classify_main(\n",
        "        folder_path    = data_path, \n",
        "        output_dir     = output_dir, \n",
        "        json_file_path = json_file_path, \n",
        "        bins_number = bins_number,\n",
        "        model_type = model_type, \n",
        "        tag = tag\n",
        "        )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Classify Single Image with Single Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Specify path to single image to be classified in data_path\n",
        "#data_path    = '../path/to/image/file'\n",
        "# Or test with sample image from dataset\n",
        "data_path    = './datasets/testdata/not-pixel-art/https___i.pinimg.com_originals_f3_bb_e6_f3bbe6fa7aa5b9c925bb36954dc8786c.jpg'\n",
        "output_dir     = './output/classification_single_image_single_model'\n",
        "json_file_path = './output/input-metadata.json'\n",
        "bins_number    = 10\n",
        "# Specify the type of model\n",
        "model_type = 'torch-logistic-regression'\n",
        "# Specify the tag string\n",
        "tag = 'not-pixel-art'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "classify_main(\n",
        "        folder_path    = data_path, \n",
        "        output_dir     = output_dir, \n",
        "        json_file_path = json_file_path, \n",
        "        bins_number = bins_number,\n",
        "        model_type = model_type, \n",
        "        tag = tag \n",
        "        )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Classify Images Data in Folder with All Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Specify path to folder containing images data in data_path variable\n",
        "# data_path = '../path/to/image/data/folder/'\n",
        "# Or test with images in dataset\n",
        "data_path    = dataset_path\n",
        "output_dir     = './output/classification_single_image_single_model'\n",
        "json_file_path = './output/input-metadata.json'\n",
        "bins_number    = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from model_api.model_api import ModelApi\n",
        "# Creating model object\n",
        "model_api = ModelApi()\n",
        "\n",
        "# Get list of model type and tag pair\n",
        "type_tag_pair = model_api.get_type_tag_pair() \n",
        "\n",
        "for model_type, tag in type_tag_pair:\n",
        "        classify_main(\n",
        "                folder_path    = data_path, \n",
        "                output_dir     = output_dir, \n",
        "                json_file_path = json_file_path, \n",
        "                bins_number = bins_number,\n",
        "                model_type = model_type, \n",
        "                tag = tag \n",
        "                )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "iWUepQsbWrT1"
      },
      "source": [
        "### Classification for 'other-validation' Folder (pre-computed CLIP embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvcwd-mVQ_A8"
      },
      "outputs": [],
      "source": [
        "# Specify path to dataset folder containing 'other-validation' folder in dataset_path variable\n",
        "dataset_path = dataset_path\n",
        "other_validation_path = os.path.join(dataset_path,'other-validation')\n",
        "output_dir     = './output/classification_other_validation'\n",
        "json_file_path =  './output/input-metadata.json'\n",
        "bins_number    = 10\n",
        "# Specify the type of model\n",
        "model_type = 'ovr-logistic-regression'\n",
        "# Specify the tag string\n",
        "tag = 'not-pixel-art'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hj7cPMRThnLC",
        "outputId": "df64e9ed-cc42-4e3f-f741-a12bfb50da60"
      },
      "outputs": [],
      "source": [
        "classify_main(\n",
        "        folder_path    = other_validation_path, \n",
        "        output_dir     = output_dir, \n",
        "        json_file_path = json_file_path, \n",
        "        bins_number    = bins_number, \n",
        "        model_type = model_type, \n",
        "        tag = tag \n",
        "        )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Classify Data for ZIP Archives (Stage 4)\n",
        "Running the classifier if the image data is either in .zip archived format or containing images archived in .zip format. The script will loop over every image and make the classification for it using every binary classification model. Running the classifier can be performed from command line interface (CLI) or within Python runtime as shown in the following examples."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Running the Classifier for ZIP Archive from Command Line Interface (CLI Version)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python ./image-tagging-pipeline/classify_zip/classify_zip.py --directory=./datasets/testdata.zip --metadata_json=./output/input-metadata.json --output=./output --output_bins=10 --model_type=ovr-logistic-regression --tag=not-pixel-art"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### CLI Arguments\n",
        "\n",
        "* `directory` _[string]_ - _[required]_ - The path to the images folder or images .zip file. \n",
        "* `metadata_json` _[string]_ - _[required]_ - The path to the metadata json file for CLIP embeddings. \n",
        "* `output` _[string]_ - _[optional]_ - The path to the output directory for the inference results. \n",
        "* `model_type` _[string]_ - _[required]_ - The type of the model (example: `ovr-logistic-regression`, `ovr-svm`, `torch-logistic-regression`)\n",
        "* `tag` _[string]_ - _[required]_ - Tag string (example: `pos-character`, `pos-environmental-space`, etc).\n",
        "* `output_bins` _[int]_ - _[optional]_ -  The number of bins of the results for each model.\n",
        "\n",
        "If the `--output` argument is not specified, the classification / inference result will be placed at `./output/tagging_output` folder. Time stamp will be appended to folder name (for example: `./output/tagging_output_2023_1_21_0_56`). In addition, the SQLite database named `zip_score_cache.sqlite` with table named `zip_score_cache` containing file name, file path, archive path, type of file, hash, model type, tag name and tag score for given images will be created in the `output` folder. \n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Running the Classifier for ZIP Archive (from Python Runtime)\n",
        "### Variables for Classifier\n",
        "* `data_path` _[string]_ - _[required]_ - The path to the images data folder or single image file'. \n",
        "* `json_file_path` _[string]_ - _[required]_ - The path to the metadata json file for CLIP embeddings. \n",
        "* `output_dir` _[string]_ - _[optional]_ - The path to the output directory for the inference results. \n",
        "* `model_type` _[string]_ - _[required]_ - The type of the model (example: `ovr-logistic-regression`, `ovr-svm`, `torch-logistic-regression`)\n",
        "* `tag` _[string]_ - _[required]_ - Tag string (example: `pos-character`, `pos-environmental-space`, etc).\n",
        "* `bins_number` _[int]_ - _[optional]_ -  The number of bins of the results for each model."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9nsNclcPX49V"
      },
      "source": [
        "### Classify Images Data in ZIP Archive with Single Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDRrhjs4wTkw"
      },
      "outputs": [],
      "source": [
        "# Specify the path to the images data in folder_path\n",
        "# data_path    = '../path/to/data.zip'\n",
        "# Or test with images data in ZIP archived dataset\n",
        "data_path = './datasets/testdata.zip'\n",
        "output_dir     = './output'\n",
        "json_file_path = './output/input-metadata.json'\n",
        "bins_number    = 5\n",
        "# Specify the type of model\n",
        "model_type = 'ovr-logistic-regression'\n",
        "# Specify the tag string\n",
        "tag = 'not-pixel-art'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AwyCnb0dXSGc"
      },
      "outputs": [],
      "source": [
        "classify_main_zip(\n",
        "        folder_path    = data_path, \n",
        "        output_dir     = output_dir, \n",
        "        json_file_path = json_file_path, \n",
        "        bins_number    = bins_number, \n",
        "        model_type = model_type, \n",
        "        tag = tag\n",
        "        )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Classify Images Data in ZIP Archive with All Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Specify the path to the images data in folder_path\n",
        "# data_path    = '../path/to/data.zip'\n",
        "# Or test with images data in ZIP archived dataset\n",
        "data_path = './datasets/testdata.zip'\n",
        "output_dir     = './output'\n",
        "json_file_path = './output/input-metadata.json'\n",
        "bins_number    = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from model_api.model_api import ModelApi\n",
        "# Creating model object\n",
        "model_api = ModelApi()\n",
        "\n",
        "# Get list of model type and tag pair\n",
        "type_tag_pair = model_api.get_type_tag_pair() \n",
        "\n",
        "for model_type, tag in type_tag_pair:\n",
        "        classify_main_zip(\n",
        "                folder_path    = data_path, \n",
        "                output_dir     = output_dir, \n",
        "                json_file_path = json_file_path, \n",
        "                bins_number = bins_number,\n",
        "                model_type = model_type, \n",
        "                tag = tag \n",
        "                )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get Score for Images Data in ZIP Archive with Single Model (Tag) and Run Function Based on Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sys.path.insert(0, './image-tagging-pipeline/classify_zip/')\n",
        "from classify_zip import zip_gen\n",
        "from classify_zip_helper_functions import get_single_tag_score, get_clip, get_classifier_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Specify ZIP archive containing images data\n",
        "folder_path    = './datasets/testdata.zip'\n",
        "# Specify the type of model\n",
        "model_type = 'ovr-logistic-regression'\n",
        "# Specify the tag string\n",
        "tag = 'not-pixel-art'\n",
        "# Score threshold to run the function\n",
        "th_score       = 0.2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def any_function_to_run(score):\n",
        "    '''Function to run when certain prob_score is met'''\n",
        "    print ('OK')\n",
        "    pass    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "clip_model , preprocess , device = get_clip(clip_model_type= 'ViT-L-14',pretrained= 'openai')\n",
        "model = get_classifier_model(model_type = model_type, tag = tag)\n",
        "print (model)\n",
        "\n",
        "# If model not found then return\n",
        "if model != {}:\n",
        "    # Loop through each zip file.\n",
        "    for file in [folder_path]:\n",
        "        # Generating images\n",
        "        for img, img_file_name in zip_gen(file):\n",
        "            # Calculate score\n",
        "            score = get_single_tag_score(img, img_file_name, model, clip_model, preprocess, device)\n",
        "            print (f'[INFO] Score: {score}')\n",
        "            if th_score < score:\n",
        "                any_function_to_run(score)\n",
        "else:\n",
        "    print ('[INFO]: Model not found. No classification performed.')\n",
        "\n",
        "print(\"[INFO] Finished.\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ZIP Archive: Reading Image Files, Compute CLIP and Send to Single Classifier (based on Type and Tag)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Import Required Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.insert(0, './image-tagging-pipeline/classify_zip/')\n",
        "import os\n",
        "import datetime\n",
        "import numpy as np\n",
        "from classify_zip import zip_gen as zip_image_iterator\n",
        "from classify_zip_helper_functions import file_to_hash, load_json, get_clip, get_classifier_model, clip_image_features, classify_image_prob, get_bins_array, find_bin, make_dir"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Specify ZIP Archive Location, Model Type and Tag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Specify ZIP archive containing images data\n",
        "zip_file_path = './datasets/testdata.zip'\n",
        "# Specify folder path to write classified images\n",
        "output_dir = './output'\n",
        "# Metadata json file location\n",
        "json_file_path = './output/input-metadata.json'\n",
        "# Specify the type of model\n",
        "model_type = 'ovr-logistic-regression'\n",
        "# Specify the tag string\n",
        "tag = 'not-pixel-art'\n",
        "# Number of classification score (probability) bins\n",
        "n_bins = 10"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create Classifier and CLIP Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get classifier model\n",
        "model = get_classifier_model(model_type = model_type, tag = tag)\n",
        "if model != {}:\n",
        "    classifier = model['classifier']\n",
        "    torch_model = 'torch' in model['model_type']\n",
        "    # Get CLIP model, to calculate CLIP embeddings if it's not in .json metadata file.\n",
        "    clip_model , preprocess , device = get_clip(clip_model_type= 'ViT-L-14',pretrained= 'openai')\n",
        "    # Creating bins\n",
        "    bins  = get_bins_array(n_bins)\n",
        "else:\n",
        "    print ('[INFO]: Model not found. Unable to perform classification')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reading, Compute CLIP and Send to Single Classifier for Each File in ZIP Archive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Loop through each zip file.\n",
        "for file in [zip_file_path]:\n",
        "    # Reading image files from ZIP archive\n",
        "    for img, img_file_name in zip_image_iterator(file):\n",
        "\n",
        "        # Hash\n",
        "        hash_id = file_to_hash(img, img_file_name)\n",
        "\n",
        "        # Load the .json file.\n",
        "        metadata_json_obj = load_json(json_file_path)\n",
        "\n",
        "        # Clip features\n",
        "        try : \n",
        "            # Check whether the hash_id exists in json file.\n",
        "            image_features = np.array(metadata_json_obj[hash_id][\"embeddings_vector\"]).reshape(1,-1) \n",
        "        except:\n",
        "            # hash_id does not exist in json file. Calculate image features.\n",
        "            image_features = clip_image_features(img, img_file_name, clip_model,preprocess,device) \n",
        "\n",
        "        # Calculate probability score\n",
        "        score = classify_image_prob(image_features, classifier, torch_model=torch_model)\n",
        "        print (score)\n",
        "\n",
        "        # Get the bins \n",
        "        tag_bin, _= find_bin(bins , score) # get the bins \n",
        "        print (tag_bin)\n",
        "\n",
        "        # Create folder for writing classified\n",
        "        timestamp = datetime.datetime.now() \n",
        "        output_sub_dir = (f'tagging_output-{timestamp.year}_{timestamp.month}_{timestamp.day}_{timestamp.hour}_{timestamp.minute}_{timestamp.second}')\n",
        "        tag_name_out_folder = make_dir([output_dir, output_sub_dir, f'{model_type}',f'{tag}',tag_bin])\n",
        "    \n",
        "        # Saving the image to file\n",
        "        file_path = os.path.join(tag_name_out_folder, os.path.basename(img_file_name))\n",
        "        img.save(file_path)\n",
        "        print (f'[INFO] File {file_path} saved')\n",
        "\n",
        "print(\"[INFO] Finished.\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Using Classifier Model API"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Model API contains function that accesses existing classifier model pickle files."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create Classifier Model API Object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from model_api.model_api import ModelApi\n",
        "\n",
        "# Create model loader object with default model_path='./output/models/'\n",
        "model_api = ModelApi()\n",
        "# Or specify model_path explicitly'\n",
        "# model_api = ModelApi(model_path='./output/models')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get List of Model Types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_types = model_api.get_model_types()\n",
        "print (model_types)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get List of Tags Based on Model Type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_type = (model_types[0])\n",
        "tags = model_api.get_tags_by_model_type(model_type)\n",
        "print (tags)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get List of Type and Tag Pairs from All Models'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "type_tag_pair = model_api.get_type_tag_pair()\n",
        "print (type_tag_pair)\n",
        "'''\n",
        "type_tag_pair is a list of tupple with the following structure\n",
        "[(<model_type>,<tag>)]\n",
        "'''"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get Model Based On Model Type and Tag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Specify model type and tag\n",
        "model_type, tag = type_tag_pair[0]\n",
        "# Get the model dictionary\n",
        "model = model_api.get_model_by_type_tag(model_type, tag)\n",
        "print(model)\n",
        "'''\n",
        "Model is a dictionary with the following structure\n",
        "{'classifier' : <model object>,\n",
        "'model_type' : <model type string>,\n",
        "'train_start_time' : <training start time datetime object>\n",
        "'tag' : <tag string>\n",
        "}\n",
        "'''"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get Models Dictionary for All Model Pickle Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_dict = model_api.get_models_dict()\n",
        "print(models_dict)\n",
        "'''\n",
        "Example stucture of models_dict\n",
        "{<model_name>: \n",
        "    {'classifier' : <model object>,\n",
        "    'model_type' : <model type string>,\n",
        "    'train_start_time' : <training start time datetime object>\n",
        "    'tag' : <tag string>\n",
        "    }\n",
        "}\n",
        "'''"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Other Examples"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Get Files List from Folder or ZIP Archive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "# Specify the path to the images data in the folder_path variable\n",
        "folder_path    = './datasets/testdata.zip'\n",
        "\n",
        "def fetch_file_paths(data_file):\n",
        "    '''Yielding contained file paths in data_file'''\n",
        "\n",
        "    if data_file.endswith('.zip'):\n",
        "\n",
        "        # Selected data_dir is a zip archive\n",
        "        with ZipFile(data_file) as archive:\n",
        "            '''Getting archive details'''\n",
        "            # Listing content\n",
        "            entries = archive.infolist()\n",
        "\n",
        "            for entry in entries:\n",
        "                # Do for every content in the zip file\n",
        "                if not entry.is_dir():\n",
        "                    \n",
        "                    with archive.open(entry) as file:\n",
        "\n",
        "                        if entry.filename.lower().endswith(('.zip')):\n",
        "                            # Another zip file found in the content.\n",
        "                            with ZipFile(file) as sub_archive:\n",
        "                                '''Getting archive details'''\n",
        "                                sub_entries = sub_archive.infolist()\n",
        "                                for sub_entry in sub_entries:\n",
        "                                    with sub_archive.open(sub_entry) as sub_file:\n",
        "                                        img_file_name = f'{data_file}/{sub_entry.filename}'\n",
        "                                        yield (img_file_name)\n",
        "\n",
        "                        else:\n",
        "                            # Should be image file.\n",
        "                            img_file_name = entry.filename\n",
        "                            yield (img_file_name)\n",
        "    else:\n",
        "        # Should be image file\n",
        "        yield data_file\n",
        "\n",
        "def get_file_paths(data_dir):\n",
        "\n",
        "    # Placeholder for file in data_dir\n",
        "    dir_list = []\n",
        "\n",
        "    if not os.path.isfile(data_dir):\n",
        "        # A normal directory\n",
        "        for root, dirs, files in os.walk(data_dir):\n",
        "            for file in files:\n",
        "                dir_list.append(os.path.join(root, file))\n",
        "    else:\n",
        "        # A single file (could be a zip archive or image)\n",
        "        dir_list = [data_dir]\n",
        "\n",
        "    # Placeholder for file_path for files found\n",
        "    file_path_list = []\n",
        "\n",
        "    for file in dir_list:\n",
        "        for file_path in fetch_file_paths(file):\n",
        "            print (f'File: {file_path}')\n",
        "            file_path_list.append(file_path)\n",
        "    \n",
        "    return file_path_list\n",
        "\n",
        "get_file_paths(folder_path)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Get List of File Hash_ID from Tag Cache Based on List of Models or Specific Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from clip_cache.cache_tag import TagCache\n",
        "from model_api.model_api import ModelApi\n",
        "\n",
        "# Specify path to tag cache file\n",
        "tag_cache_path = './output/tag_cache.sqlite'\n",
        "\n",
        "# Output placeholder\n",
        "model_tag_cache_pair = {}\n",
        "\n",
        "try:\n",
        "    # Create tag cache object\n",
        "    tag_cache = TagCache()\n",
        "    # Create model api object\n",
        "    model_api=ModelApi()\n",
        "\n",
        "    # Getting models\n",
        "    models_dict = model_api.get_models_dict()\n",
        "    '''\n",
        "    Example stucture of models_dict\n",
        "    {<model_name>: \n",
        "        {'classifier' : <model object>,\n",
        "        'model_type' : <model type string>,\n",
        "        'train_start_time' : <traing start time datetime object>\n",
        "        'tag' : <tag string>\n",
        "        }\n",
        "    }\n",
        "    '''\n",
        "\n",
        "    # Get tags from models_dict\n",
        "    for model in models_dict:\n",
        "        # Get list of images (hash_IDs) based on each model's tag name\n",
        "        hash_ids = tag_cache.get_hash_by_tag(db_path = tag_cache_path, tag = models_dict[model]['tag'])\n",
        "        # Append list of hash IDs to the result dict\n",
        "        model_tag_cache_pair[model] = hash_ids\n",
        "    \n",
        "    # Output\n",
        "    print(json.dumps(model_tag_cache_pair, indent=2))\n",
        "\n",
        "except Exception as e:\n",
        "    print (f'[ERROR] {e}: Getting data from tag cache failed')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "c518711542db1b7752d0b1005bb6b1db13084b2ce60111ae8895922158ddc3d4"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
